"""
Siamese network to detect if two images are of the same person.
Uses the CNN from images.py
"""

import enum
import os

import torch
import torch.nn as nn
import sklearn
import numpy as np
from torch.utils import data
from torch.utils.data import DataLoader, Dataset
import matplotlib.pyplot as plt

# Our CNN is in images
import images


def plot_loss(history):
  """
  Plot loss values generated by model.fit
  """
  plt.plot(history["train_loss"], label='train_loss')
  plt.plot(history["val_loss"], label='val_loss')
  plt.plot(history["accuracy"], label='accuracy')
  plt.ylim([0, 5])
  plt.xlabel('Epoch')
  plt.ylabel('Loss/Accuracy')
  plt.legend()
  plt.grid(True)
  plt.show()

class SiameseNetwork(nn.Module):
    def __init__(self, cnn = None):
        super().__init__()
        if cnn is None:
            cnn = images.ConvNeuralNetwork(64,40)
        self.cnn = cnn
        self.linear = nn.Linear(1, 1)
        self.pair_distance = nn.PairwiseDistance()
        self.cos_distance = nn.CosineSimilarity()

    def forward(self, x: torch.Tensor):
        o1 = self.cnn(x[:,[0]])
        o2 = self.cnn(x[:,[1]])
        #dist = self.pair_distance(o1, o2, keepdim=True)
        dist = self.cos_distance(o1, o2).reshape(o2.shape[0],1)
        #print(f"distance: {dist}")
        x = self.linear(dist)
        #print(f"linear factored {x}")
        return x


def load_cnn() -> images.ConvNeuralNetwork:
    return images.load_cnn(use_faces_data=True)

class ImagePairDataset(Dataset):
    def __init__(self, root: str = "data", train: bool = True):
        self.image_data = sklearn.datasets.fetch_olivetti_faces(data_home="data")
        self.data = []

        # Map labels to list of indexes
        image_dict = {}
        for index, label in enumerate(self.image_data.target):
            if label not in image_dict:
                image_dict[label] = []
            image_dict[label].append(index)

        # Generate pair info for training - (index1, index2, pos/neg)
        for index, label in enumerate(self.image_data.target):
            # Generate positive pair
            entry1 = (index, np.random.choice(image_dict[label]).item(), 0)

            # Generate negative pair
            alt_labels = [ x for x in image_dict.keys() if x != label ]
            alt_label = np.random.choice(alt_labels)
            alt_image_index = np.random.choice(image_dict[alt_label]).item()
            entry2 = (index, alt_image_index, 1)

            # Populate training or validation data
            if ((train and index % 10 != 0) or
                (not train and index % 10 == 0)):
                # Add to data
                self.data.append(entry1)
                self.data.append(entry2)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        entry = self.data[idx]
        image1 = self.image_data.images[entry[0]]
        image2 = self.image_data.images[entry[1]]
        images = np.array([image1, image2])
        label = entry[2]
        return torch.Tensor(images), torch.Tensor([label])

def train(model):
    loss_fn = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=5.e-3)
    train_loader = DataLoader(ImagePairDataset(train=True), batch_size=10)
    validation_loader = DataLoader(ImagePairDataset(train=False), batch_size=10)


    for X, y in train_loader:
        print(f"Shape of X [N, C, H, W]: {X.shape}")
        print(f"Shape of y: {y.shape} {y.dtype}")
        break

    epochs = 100
    history = {}
    history["train_loss"] = []
    history["val_loss"] = []
    history["accuracy"] = []

    for e in range(epochs):

        # Run training data
        model.train()
        running_loss = 0
        size = len(train_loader.dataset)
        for batch, (X, y) in enumerate(train_loader):
            X, y = X.to(torch.get_default_device()), y.to(torch.get_default_device())

            # Compute prediction error
            pred = model(X)
            loss = loss_fn(pred, y)
            running_loss += loss.item() * X.shape[0]

            # Backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        history["train_loss"].append(running_loss / len(train_loader.dataset))

        # Test with validation data
        size = len(validation_loader.dataset)
        num_batches = len(validation_loader)
        model.eval()
        test_loss, correct = 0, 0
        with torch.no_grad():
            for X, y in validation_loader:
                X, y = X.to(torch.get_default_device()), y.to(torch.get_default_device())
                pred = model(X)
                test_loss += loss_fn(pred, y).item()
                pred = torch.round(pred)
                for index in range(len(pred)):
                    if pred[:,0][index] == y[:,0][index]:
                        correct += 1
        test_loss /= num_batches
        correct /= size
        history["val_loss"].append(test_loss)
        history["accuracy"].append(correct)
        print(f"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \n")

    return history

def run_preditions(model):
    train_loader = DataLoader(ImagePairDataset(train=True), batch_size=10)
    for X, y in train_loader:
        with torch.no_grad():
            X, y = X.to(torch.get_default_device()), y.to(torch.get_default_device())
            pred = model(X)
        fig, axs = plt.subplots(nrows=10, ncols=3)
        X = X.to("cpu")
        y = y.to("cpu")
        for index, ax in enumerate(axs.flat):
            if index % 3 == 0:
                ax.imshow(X[int(index/3),0])
            elif index % 3 == 1:
                ax.imshow(X[int(index/3),1])
            else:
                ax.set_axis_off()
                p = pred[int(index/3),0].item()
                a = int(y[int(index/3),0].item())
                if p < 0.5:
                    if a == 0:
                        text = "CORRECT: "
                    else:
                        text = "NOT CORRECT: "
                    text += "Match: %.2f" % p
                else:
                    if a == 1:
                        text = "CORRECT: "
                    else:
                        text = "NOT CORRECT: "
                    text += "No Match: %.2f" % p
                ax.text(0, 0.5, text)
        plt.show()
            
if __name__ == "__main__":
    device = "cuda" if torch.cuda.is_available() else "cpu"
    torch.set_default_device(device)
    path = os.path.join("data", "siamese.pt")
    if os.path.isfile(path):
        model = SiameseNetwork()
        model.load_state_dict(torch.load(path, weights_only=True))
        run_preditions(model)
    else:
        cnn = None
        #cnn = load_cnn()
        model = SiameseNetwork(cnn)
        loss_history =train(model)
        print("Saving model")
        torch.save(model.state_dict(), path)
        plot_loss(loss_history)



